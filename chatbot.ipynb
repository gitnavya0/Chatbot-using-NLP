{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nlp-utils"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yPUzHoLmKCee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "import pandas as pd\n",
        "import nlp_utils as nu\n",
        "import matplotlib.pyplot as plt\n",
        "# Loading necessary libraries"
      ],
      "metadata": {
        "id": "Za7ZXZ3KGqWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/dialogs.txt\", \"r\")\n",
        "print(f.read())\n",
        "# reading the data"
      ],
      "metadata": {
        "id": "CDuX_AkvGsBk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/dialogs.txt',names=('Query','Response'),sep=('\\t'))\n",
        "# Reading the data"
      ],
      "metadata": {
        "id": "gEC9vDy-Gt_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "0ia-L0sUHD0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Text=df['Query']"
      ],
      "metadata": {
        "id": "aGhYR_s1HFvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "XbsgY_qSMpgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sid = SentimentIntensityAnalyzer()\n",
        "for sentence in Text:\n",
        "     print(sentence)\n",
        "\n",
        "     ss = sid.polarity_scores(sentence)\n",
        "     for k in ss:\n",
        "         print('{0}: {1}, ' .format(k, ss[k]), end='')\n",
        "     print()"
      ],
      "metadata": {
        "id": "_Al5hCPeHHFn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = SentimentIntensityAnalyzer()\n",
        "df['rating'] = Text.apply(analyzer.polarity_scores)\n",
        "df=pd.concat([df.drop(['rating'], axis=1), df['rating'].apply(pd.Series)], axis=1)\n",
        "### Creating a dataframe."
      ],
      "metadata": {
        "id": "L2lr2ZvMHIge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "# importing word cloud"
      ],
      "metadata": {
        "id": "iynMF13OHNQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wordcloud(df, label):\n",
        "\n",
        "    subset=df[df[label]==1]\n",
        "    text=df.Query.values\n",
        "    wc= WordCloud(background_color=\"black\",max_words=1000)\n",
        "\n",
        "    wc.generate(\" \".join(text))\n",
        "\n",
        "    plt.figure(figsize=(20,20))\n",
        "    plt.subplot(221)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Words frequented in {}\".format(label), fontsize=20)\n",
        "    plt.imshow(wc.recolor(colormap= 'gist_earth' , random_state=244), alpha=0.98)\n",
        "# visualising wordcloud"
      ],
      "metadata": {
        "id": "eQDB0Nf1HPGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "5T7bIBViHU-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())"
      ],
      "metadata": {
        "id": "B-We0IA7HYFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_n = lambda x: re.sub(\"\\n\", \" \", x)"
      ],
      "metadata": {
        "id": "ycapOY07HZ12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_non_ascii = lambda x: re.sub(r'[^\\x00-\\x7f]',r' ', x)"
      ],
      "metadata": {
        "id": "udsGHdc6Hbeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)"
      ],
      "metadata": {
        "id": "NrTqz8NMHc0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Query'] = df['Query'].map(alphanumeric).map(punc_lower).map(remove_n).map(remove_non_ascii)"
      ],
      "metadata": {
        "id": "onwp1_NsHeO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Response'] = df['Response'].map(alphanumeric).map(punc_lower).map(remove_n).map(remove_non_ascii)"
      ],
      "metadata": {
        "id": "vdPniJqZHgFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows',3800)"
      ],
      "metadata": {
        "id": "DZRTiwkwHiPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imp_sent=df.sort_values(by='compound', ascending=False)"
      ],
      "metadata": {
        "id": "23VNyEp6HsdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_sent=df.sort_values(by='pos', ascending=False)"
      ],
      "metadata": {
        "id": "K58WV7lxHuGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neg_sent=df.sort_values(by='neg', ascending=False)"
      ],
      "metadata": {
        "id": "wbgJfgB2HxN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neu_sent=df.sort_values(by='neu', ascending=False)"
      ],
      "metadata": {
        "id": "dS7V6UeWH1hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "AZdGF4ZlH4YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "unSK4fV3H4qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factors = tfidf.fit_transform(df['Query']).toarray()"
      ],
      "metadata": {
        "id": "MPWnzm5FH51A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_distances"
      ],
      "metadata": {
        "id": "BT97IsP9H8ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'who are you ?'\n",
        "def chatbot(query):\n",
        "    # step:-1 clean\n",
        "    query = nu.lemmatization_sentence(query)\n",
        "    # step:-2 word embedding - transform\n",
        "    query_vector = tfidf.transform([query]).toarray()\n",
        "    # step-3: cosine similarity\n",
        "    similar_score = 1 -cosine_distances(factors,query_vector)\n",
        "    index = similar_score.argmax() # take max index position\n",
        "    # searching or matching question\n",
        "    matching_question = df.loc[index]['Query']\n",
        "    response = df.loc[index]['Response']\n",
        "    pos_score = df.loc[index]['pos']\n",
        "    neg_score = df.loc[index]['neg']\n",
        "    neu_score = df.loc[index]['neu']\n",
        "    confidence = similar_score[index][0]\n",
        "    chat_dict = {'match':matching_question,\n",
        "                'response':response,\n",
        "                'score':confidence,\n",
        "                'pos':pos_score,\n",
        "                'neg':neg_score,\n",
        "                'neu':neu_score}\n",
        "    return chat_dict"
      ],
      "metadata": {
        "id": "zRKmeh0SH-V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "NgTnorWHPFuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    query = input('USER: ')\n",
        "    if query == 'exit':\n",
        "        break\n",
        "\n",
        "    response = chatbot(query)\n",
        "    if response['score'] <= 0.2: #\n",
        "        print('BOT: Please rephrase your Question.')\n",
        "\n",
        "    else:\n",
        "        print('='*80)\n",
        "        print('logs:\\n Matched Question: %r\\n Confidence Score: %0.2f \\n PositiveScore: %r \\n NegativeScore: %r\\n NeutralScore: %r'%(\n",
        "            response['match'],response['score']*100,response['pos'],response['neg'],response['neu']))\n",
        "        print('='*80)\n",
        "        print('BOT: ',response['response'])"
      ],
      "metadata": {
        "id": "xKEjh0OfIAd-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}